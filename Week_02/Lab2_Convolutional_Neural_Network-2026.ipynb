{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **LAB 2 -** Computer Vision. Convolutional Neural Networks.\n",
        "Group: M25-RO-01\n",
        "\n",
        "Instructor: Alexey Kornaev\n",
        "\n",
        "TA: Kirill Yakovlev"
      ],
      "metadata": {
        "id": "94Wo_jSw-5BI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTRODUCTION AND THEORETICAL BACKGROUND**\n",
        "\n",
        "Today we start talking about one of the most important and fundamental concept in Computer Vision - **convolutions.**\n",
        "\n",
        "Let's start from fundamental understanding: **each kind of information usually has its own properties, which means theres exists specific methods to deal with that.** Without digging too deep in to the concept of data and information, let's assume that today's AI world is dealing with the following  types of data:\n",
        "- text\n",
        "- audio\n",
        "- images and video\n",
        "- tabular data\n",
        "- mixed type of data\n",
        "\n",
        "To distinguish them properly we focus on different characteristics, e.g. by defining what is **the unit of information** of each data type. In that sense, for text it could a token, for images - a pixel, whereas for videos it's a bit more complex, as we might consider not only pixels, but frames as well. Definitely each data type has its own inherent properties that methods are trying to deal with. On this course we will be mainly tied with an image data world (and a bit with videos as well) as well as on methods to process that.\n",
        "\n",
        "What is the main idea that stands behind convoltion creation? Well, the answer is not that sophisticated - **we want to extract or make something useful (e.g. transformation) to solve some tasks and problems.** From the perspective of ML, extracting something useful to make our model more efficient in solving our initial task (classification, generation, segmentation, etc.)\n",
        "\n",
        "In that sense we can consider images as matrices with **ordered set of pixels**, where each of them has a corresponding value of intensity in each color channel, which can be also considered as a separate matrix (fr, fg, fb).\n",
        "So we want to extract features from images or matrix-like type of data.\n",
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/56/RGB_channels_separation.png\" width=\"350\" height=\"300\">\n",
        "\n",
        "A pixel intensity usually exists in interval between 0 and 255 in each color channel. Such structure makes it possible to represent a numerous number of colors, where:\n",
        "\n",
        "- black corresponds to a vector of zeros - [0,0,0]\n",
        "- white is represented as [255, 255, 255]\n",
        "\n",
        "The image itself can be represented as H x W x C, where H is a height of image or number of pixel vectors in matrix, W - width or number of pixels in each vector, C - number of channels or number of pixel matrices.\n",
        "\n",
        "Remember that RGB is not the single format we can use to represent image data, but it is straight and understandable for a human perception. Additionally you can read about other color formats, especially take an attention to a **LAB** representation.\n",
        "\n",
        "https://opencv.org/blog/color-spaces-in-opencv/\n",
        "\n",
        "BUT: how do we use such information inside our images? Well, at first sight we can just squeeze our image into a row vector and apply some classical methods like Multi-Layer Perceptron, but such \"trivial\" has some problems:\n",
        "\n",
        "- each pixel will be processed by a separate parameter that enormously increase number of parameters and make our solution completely **indigestible** for high-dimensional cases\n",
        "\n",
        "- we lose **\"spatial\" information** of the image\n",
        "\n",
        "But what does that mean? Let's take a look on a simple set of images:\n",
        "\n",
        "<img src=\"https://yastatic.net/s3/education-portal/media/puppy_a1d259493d_708f608dce.webp\" width=\"100\" height=\"100\">\n",
        "\n",
        "<img src=\"https://yastatic.net/s3/education-portal/media/shifted_puppy_c27db8708f_ca16064a3b.webp\" width=\"100\" height=\"100\">\n",
        "\n",
        "<img src=\"https://yastatic.net/s3/education-portal/media/scaled_puppy_d6c7abac44_a80f12b60e.webp\" width=\"100\" height=\"100\">\n",
        "\n",
        "<img src=\"https://yastatic.net/s3/education-portal/media/flipped_puppy_a8a6029dce_c8300e6bd9.webp\" width=\"100\" height=\"100\">\n",
        "\n",
        "What have you noticed? Despite we have the same dog on each image, it can be differently located or might be changed in some simple way (mirrored, croped, etc.). Is it still a problem for the MLP? **NO**, because of [universal approximation theorem](https://www.deep-mind.org/2023/03/26/the-universal-approximation-theorem/). But it makes our solution TOO complex.\n",
        "\n",
        "So definitely we cannot ignore those potential cases, but methods should be **invariant** to such tranformations and a with reasonable computational complexity.\n",
        "\n",
        "This is where **Linear Shift-Invariant System** (LSIS) comes to the play. Such systems have **two** fundamental properties:\n",
        "\n",
        "1. **Linearity** - System follows a superposition principle\n",
        "\n",
        "if $f_{1}(t)$ produces response $g_{1}(t)$ and $f_{2}(t)$ produces response\n",
        "$g_{2}(t)$, then any linear combination $a*f_{1}(t)$ + $b*f_{2}(t)$ will produce the response $a*g_{1}(t)$ + $b*g_{2}(t)$, where a and b are constants. IOW, a linear map or linear function f(x) is a function that satisfies the two properties:\n",
        "\n",
        "- Additivity: f(x + y) = f(x) + f(y)\n",
        "- Homogeneity: f(αx) = α f(x) for all α\n",
        "\n",
        "\n",
        "2. **Shift-Invariance** - A shift-invariant system is one where a shift in the independent variable of the input signal causes a corresponding shift in the output signal. So simply if we shift the input in time then the output is shifted by the same amount.\n",
        "\n",
        "f(x(t)) = y(t), shift invariance means that f(x(t + a)) = y(t + a)\n",
        "\n",
        "<img src=\"https://i.postimg.cc/63L3Nt3G/LSIS.png\" width=\"300\" height=\"300\">\n",
        "\n",
        "Simple is that.\n",
        "\n"
      ],
      "metadata": {
        "id": "UQhP6eFmKYnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok let's switch to convolutions itlself. We will not dive very deeply about convolution's structure and why it is as it is, as many things have appeared through time and methodical evolution.\n",
        "\n",
        "**Convolution** is nothing else but a mathematical operation of integration of convolving one function through the other.\n",
        "\n",
        "<img src=\"https://i.postimg.cc/Nj3J3wZH/Convolution.png\" width=\"750\" height=\"200\">\n",
        "\n",
        "Practically we turn to convolution filters that exist as kernels that sit on top of the image and slides from left to right and up to down, applying a mathematical operation at each (x, y) - coordinate in the original image.\n",
        "Kernel is just a small (usually) $N x N$ matrix. It allows to structurally transform each pixel of an image.\n",
        "\n",
        "Let's take a look on the example.\n",
        "\n",
        "\n",
        "<img src=\"https://i.postimg.cc/3RXZ0HPD/2D-Convolution-Animation.gif\" width=\"250\" height=\"200\">\n",
        "\n",
        "<img src=\"https://i.postimg.cc/nzNCxsdn/matrix.png\" width=\"550\" height=\"250\">\n",
        "\n",
        "\n",
        "The area of ​​the image that our neural network “looks” at is called the **receptive field** (yellow zone), and we often have to think about it in computer vision problems.\n",
        "\n",
        "Finally, linearity of convolutions provide the following properties:\n",
        "\n",
        "1. Commutative → a * b = b * a\n",
        "2. Associative → (a * b) * c = a * (b * c)\n",
        "\n",
        "How does it help us?\n",
        "If we are doing series of convolutions, then we can simplify our system\n",
        "\n",
        "$f → conv1 → conv2→ g ⇔ f → conv1 * conv2→ g ⇔ f → conv2* conv1→ g$\n",
        "\n",
        "Ok, simply this is the basics that stands behind convolution. All other concepts like **padding**, **activation maps**, **pooling**, etc. is better absorbed during practices. Let's switch to the practical part..."
      ],
      "metadata": {
        "id": "TipoLS8NiCqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's take a simple classification case for a better understading using a pytorch framework.**"
      ],
      "metadata": {
        "id": "kvX7cYkwqVHM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B2Il-BRogP-V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's start with sequential transformations. Do you know what they are exactly doing?**"
      ],
      "metadata": {
        "id": "QwaXyJuQGROs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_cifar_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(), # randomly flip an image horizontally (left to right) with a specified probability\n",
        "    transforms.RandomCrop(32, padding=4), # taking a random NxN pixel crop\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # normalizes an image tensor by mapping its pixel values from a [0, 1] range to a [-1, 1] range\n",
        "])\n",
        "\n",
        "transform_cifar_test = transform_cifar_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "# Uploading data and finalizing dataset preparation\n",
        "\n",
        "cifar10_train = datasets.CIFAR10(root='data', train=True, transform=transform_cifar_train, download=True)\n",
        "cifar10_test = datasets.CIFAR10(root='data', train=False, transform=transform_cifar_test, download=True)\n",
        "\n",
        "cifar10_loader_train = DataLoader(cifar10_train, batch_size=32, shuffle=True)\n",
        "cifar10_loader_test = DataLoader(cifar10_test, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oXbcGGEFiOb",
        "outputId": "3cf10bd2-e0b7-4277-9f24-7d71e23dc867"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 43.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's start with designing our first architecture. We want to keep it as simple as possible in the first attempt gradually improving it in next sections. This CNN consists of one convolutional layer following by the max pooling layer and finalizing our model by the fully connected layer for the classification purpose.**"
      ],
      "metadata": {
        "id": "L8K8Da9EFgt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_First_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc = nn.Linear(16 * 16 * 16, 10)\n",
        "        self.out = nn.LogSoftmax(dim=1)\n",
        "        # self.out = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv(x))) # why do we need ReLU here?\n",
        "        x = x.view(-1, 16 * 16 * 16)\n",
        "        x = self.fc(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lPBe_OeCqFo_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's take a look on our model!**"
      ],
      "metadata": {
        "id": "cGHdaXU4Xwe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = My_First_CNN()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKyT3NXMEb94",
        "outputId": "72515bee-7e4e-41f6-cadf-e907e7a6afa5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My_First_CNN(\n",
            "  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  (out): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Also we can check our model out and analyze its properties using summary. Sometimes it also can help you arrange size of your layers and avoid training errors.**"
      ],
      "metadata": {
        "id": "j_6KzCK9HOL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = My_First_CNN()\n",
        "summary(model, input_size = (3,32,32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch_lEQt1HQGn",
        "outputId": "84a9c6bf-51fd-42cb-e64e-ccc2e8190f11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
            "            Linear-3                   [-1, 10]          40,970\n",
            "        LogSoftmax-4                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 41,418\n",
            "Trainable params: 41,418\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.16\n",
            "Params size (MB): 0.16\n",
            "Estimated Total Size (MB): 0.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next let's try to train our initial model and see what result we will get. Let's make a specific function for that so we can reuse it for further experiments.**"
      ],
      "metadata": {
        "id": "uApMt7GIZiDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, test_loader, optimizer, criterion = torch.nn.NLLLoss(),\n",
        "          n_epochs = 10, max_epochs_stop = 3, save_file = 'model-cifar.pt'):\n",
        "\n",
        "    # specify loss function\n",
        "    criterion = criterion\n",
        "\n",
        "    # specify optimizer\n",
        "    optimizer = optimizer\n",
        "\n",
        "    epochs_no_improve = 0\n",
        "    max_epochs_stop = max_epochs_stop\n",
        "    test_loss_min = np.inf\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "\n",
        "        # keep track of training and Test loss\n",
        "        train_loss = 0.0\n",
        "        test_loss = 0.0\n",
        "\n",
        "        train_acc = 0\n",
        "        test_acc = 0\n",
        "\n",
        "\n",
        "\n",
        "        # TRAIN STEP\n",
        "\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy (don't forget to modify if you are using Cross-Enthropy and Softmax function)\n",
        "            ps = torch.exp(output) # why we need exp?\n",
        "            topk, topclass = ps.topk(1, dim = 1)\n",
        "            equals = topclass == target.view(*topclass.shape)\n",
        "            accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
        "            train_acc += accuracy.item()\n",
        "\n",
        "            print(f'Epoch: {epoch} \\t {100 * i / len(train_loader):.2f}% complete.', end = '\\r')\n",
        "\n",
        "        # VALIDATION STEP\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        for data, target in test_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # update average Test loss\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            ps = torch.exp(output)\n",
        "            topk, topclass = ps.topk(1, dim = 1)\n",
        "            equals = topclass == target.view(*topclass.shape)\n",
        "            accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
        "            test_acc += accuracy.item()\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss/len(train_loader)\n",
        "        test_loss = test_loss/len(test_loader)\n",
        "\n",
        "        train_acc = train_acc/len(train_loader)\n",
        "        test_acc = test_acc/len(test_loader)\n",
        "\n",
        "        # print training/Test statistics\n",
        "        print('\\nEpoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f}'.format(\n",
        "            epoch, train_loss, test_loss))\n",
        "        print(f'Training Accuracy: {100 * train_acc:.2f}%\\t Test Accuracy: {100 * test_acc:.2f}%')\n",
        "\n",
        "        # save model if Test loss has decreased\n",
        "        if test_loss <= test_loss_min:\n",
        "            print('Test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            test_loss_min,\n",
        "            test_loss))\n",
        "            torch.save(model.state_dict(), save_file)\n",
        "            epochs_no_improve = 0\n",
        "            test_loss_min = test_loss\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f'{epochs_no_improve} epochs with no improvement.')\n",
        "            if epochs_no_improve >= max_epochs_stop:\n",
        "                print('Early Stopping')\n",
        "                break"
      ],
      "metadata": {
        "id": "aNNOB35FZpuS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's specify our training parameters like number of training epochs, optimzier, etc. It's up to you what you think can be specified to enhance your results**"
      ],
      "metadata": {
        "id": "4aIP4rxteRuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20 # you may increase this number to train in a final model\n",
        "optimizer = optim.Adam(model.parameters()) # Choosing optimizer. Let's choose classical Adam optimizer\n",
        "save_file_name = 'model-cifar.pt' # define name to save weights of our model"
      ],
      "metadata": {
        "id": "aPn-0IVdgwEn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Last step we can specify whether we want to train our model by CPU or GPU. In colab you can choose T4 in your Runtime type settings, but usage time is a strictly limited.**"
      ],
      "metadata": {
        "id": "c9CaPt-Egw1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "metadata": {
        "id": "GR9M8srpg5Aa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Start training...**"
      ],
      "metadata": {
        "id": "PB4pzkawltLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, cifar10_loader_train, cifar10_loader_test, optimizer = optimizer,\n",
        "      n_epochs = n_epochs, save_file = save_file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq6ehhhMb4Ri",
        "outputId": "7c9c912b-ab3f-4b26-cfaf-a1ed1c7b4114"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 \tTraining Loss: 1.428883 \tTest Loss: 1.231967\n",
            "Training Accuracy: 49.81%\t Test Accuracy: 56.11%\n",
            "Test loss decreased (inf --> 1.231967).  Saving model ...\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 1.186587 \tTest Loss: 1.170744\n",
            "Training Accuracy: 58.64%\t Test Accuracy: 59.71%\n",
            "Test loss decreased (1.231967 --> 1.170744).  Saving model ...\n",
            "\n",
            "Epoch: 3 \tTraining Loss: 1.100484 \tTest Loss: 1.142016\n",
            "Training Accuracy: 61.99%\t Test Accuracy: 60.62%\n",
            "Test loss decreased (1.170744 --> 1.142016).  Saving model ...\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 1.038417 \tTest Loss: 1.149749\n",
            "Training Accuracy: 64.08%\t Test Accuracy: 60.15%\n",
            "1 epochs with no improvement.\n",
            "\n",
            "Epoch: 5 \tTraining Loss: 0.987043 \tTest Loss: 1.099203\n",
            "Training Accuracy: 65.81%\t Test Accuracy: 62.31%\n",
            "Test loss decreased (1.142016 --> 1.099203).  Saving model ...\n",
            "\n",
            "Epoch: 6 \tTraining Loss: 0.946673 \tTest Loss: 1.080561\n",
            "Training Accuracy: 67.47%\t Test Accuracy: 62.42%\n",
            "Test loss decreased (1.099203 --> 1.080561).  Saving model ...\n",
            "\n",
            "Epoch: 7 \tTraining Loss: 0.915007 \tTest Loss: 1.063896\n",
            "Training Accuracy: 68.40%\t Test Accuracy: 62.75%\n",
            "Test loss decreased (1.080561 --> 1.063896).  Saving model ...\n",
            "\n",
            "Epoch: 8 \tTraining Loss: 0.888935 \tTest Loss: 1.073643\n",
            "Training Accuracy: 69.38%\t Test Accuracy: 63.66%\n",
            "1 epochs with no improvement.\n",
            "\n",
            "Epoch: 9 \tTraining Loss: 0.868121 \tTest Loss: 1.077595\n",
            "Training Accuracy: 70.00%\t Test Accuracy: 63.75%\n",
            "2 epochs with no improvement.\n",
            "\n",
            "Epoch: 10 \tTraining Loss: 0.848602 \tTest Loss: 1.090129\n",
            "Training Accuracy: 70.74%\t Test Accuracy: 63.15%\n",
            "3 epochs with no improvement.\n",
            "Early Stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By such trivial architecture we are still able to achieve accuracy >62% which is pretty decent given number of classes.**\n",
        "\n",
        "**But let's switch to something more advanced like DNN (Deep Neural Networks). Basically, it means we start stacking many layers sequentially making our model more complex as well as increasing it is ability to catch more advanced relations between training data and classes accordingly. BTW, what happens with a receptive field by stacking more convolution layers?**\n",
        "\n",
        "**TO make it more convenient pytorch has a special method [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) making it easier to construct more complex architectures. However, it requires some different reorganization in code from us. We can arrange this architecture as blocks for feature extraction and classification procedures.**"
      ],
      "metadata": {
        "id": "4fRUi6YYo3-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_advanced(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feature_extraction_block = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.classification_block = nn.Sequential(\n",
        "            nn.Linear(in_features= 4 * 4 * 4 * 4, out_features=10),\n",
        "        )\n",
        "        self.out = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extraction_block(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classification_block(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "o_HSa-8Wtfo2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN_advanced()\n",
        "summary(model, input_size = (3,32,32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW2qtwwnwBch",
        "outputId": "14258741-856d-4092-f6cf-189c7ad76b40"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
            "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
            "              ReLU-5           [-1, 32, 16, 16]               0\n",
            "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
            "            Conv2d-7             [-1, 16, 8, 8]           4,624\n",
            "              ReLU-8             [-1, 16, 8, 8]               0\n",
            "         MaxPool2d-9             [-1, 16, 4, 4]               0\n",
            "          Flatten-10                  [-1, 256]               0\n",
            "           Linear-11                   [-1, 10]           2,570\n",
            "       LogSoftmax-12                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 12,282\n",
            "Trainable params: 12,282\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.44\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.50\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can notice that adding new convolution layers is not associated with significant parameter increase, which is crucial when you are dealing with calculation resource limitations.**\n",
        "\n",
        "**Let's try to train our new model...**\n",
        "\n",
        "**Don't hesitate to repeat training process couple (several) times, remember that we are dealing with a LOCALLY optimal parametric system that sometimes is associated with unstable results.**"
      ],
      "metadata": {
        "id": "Jclt-6BUIQw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 30\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "save_file_name = 'model-cifar-advanced.pt'\n",
        "\n",
        "train(model, cifar10_loader_train, cifar10_loader_test, optimizer = optimizer,\n",
        "      n_epochs = n_epochs, save_file = save_file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4B0-ulvwQmj",
        "outputId": "c1635004-dd55-47ab-db0e-775ada5e62b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 \tTraining Loss: 1.547406 \tTest Loss: 1.347166\n",
            "Training Accuracy: 43.64%\t Test Accuracy: 51.67%\n",
            "Test loss decreased (inf --> 1.347166).  Saving model ...\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 1.264989 \tTest Loss: 1.190085\n",
            "Training Accuracy: 55.00%\t Test Accuracy: 57.38%\n",
            "Test loss decreased (1.347166 --> 1.190085).  Saving model ...\n",
            "\n",
            "Epoch: 3 \tTraining Loss: 1.144745 \tTest Loss: 1.099198\n",
            "Training Accuracy: 59.65%\t Test Accuracy: 61.15%\n",
            "Test loss decreased (1.190085 --> 1.099198).  Saving model ...\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 1.063494 \tTest Loss: 1.032497\n",
            "Training Accuracy: 62.66%\t Test Accuracy: 63.61%\n",
            "Test loss decreased (1.099198 --> 1.032497).  Saving model ...\n",
            "\n",
            "Epoch: 5 \tTraining Loss: 1.008829 \tTest Loss: 1.037454\n",
            "Training Accuracy: 64.57%\t Test Accuracy: 63.75%\n",
            "1 epochs with no improvement.\n",
            "\n",
            "Epoch: 6 \tTraining Loss: 0.967562 \tTest Loss: 1.007779\n",
            "Training Accuracy: 66.01%\t Test Accuracy: 64.59%\n",
            "Test loss decreased (1.032497 --> 1.007779).  Saving model ...\n",
            "\n",
            "Epoch: 7 \tTraining Loss: 0.928989 \tTest Loss: 0.958980\n",
            "Training Accuracy: 67.58%\t Test Accuracy: 66.44%\n",
            "Test loss decreased (1.007779 --> 0.958980).  Saving model ...\n",
            "\n",
            "Epoch: 8 \tTraining Loss: 0.903699 \tTest Loss: 0.953003\n",
            "Training Accuracy: 68.39%\t Test Accuracy: 66.96%\n",
            "Test loss decreased (0.958980 --> 0.953003).  Saving model ...\n",
            "\n",
            "Epoch: 9 \tTraining Loss: 0.879603 \tTest Loss: 0.985920\n",
            "Training Accuracy: 68.99%\t Test Accuracy: 65.54%\n",
            "1 epochs with no improvement.\n",
            "\n",
            "Epoch: 10 \tTraining Loss: 0.859127 \tTest Loss: 0.915498\n",
            "Training Accuracy: 70.01%\t Test Accuracy: 67.96%\n",
            "Test loss decreased (0.953003 --> 0.915498).  Saving model ...\n",
            "\n",
            "Epoch: 11 \tTraining Loss: 0.840318 \tTest Loss: 0.920071\n",
            "Training Accuracy: 70.45%\t Test Accuracy: 68.02%\n",
            "1 epochs with no improvement.\n",
            "\n",
            "Epoch: 12 \tTraining Loss: 0.824380 \tTest Loss: 0.918393\n",
            "Training Accuracy: 71.04%\t Test Accuracy: 67.88%\n",
            "2 epochs with no improvement.\n",
            "\n",
            "Epoch: 13 \tTraining Loss: 0.811938 \tTest Loss: 0.957054\n",
            "Training Accuracy: 71.64%\t Test Accuracy: 66.41%\n",
            "3 epochs with no improvement.\n",
            "Early Stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can notice adding couple new convolution layers gave us ~4.9% increase in accuracy, which is not that bad.**\n",
        "\n",
        "**This principle with a consequent applying convolution with ReLU and max pooling can be met in advanced deep architectures like VGG16 (image below). But for CIFAR10 this architecture looks exorbitantly advanced.**\n",
        "\n",
        "![](https://www.researchgate.net/profile/Jose-Cano-6/publication/327070011/figure/fig1/AS:660549306159105@1534498635256/VGG-16-neural-network-architecture.png)\n",
        "\n",
        "**Nevertheless, for real-world problems when we usually stick to already existent solutions and architectures. Pytorch provides already pretrained models for classification tasks usually pretrained on [Image Net](https://www.image-net.org/) dataset. As of today they have the following models available:**\n",
        "\n",
        "\n",
        "\n",
        "* AlexNet\n",
        "* ConvNeXt\n",
        "* DenseNet - Dense connections to improve gradient flow and feature reuse\n",
        "* EfficientNet - Compound scaling method to scale, depth, width and resolution\n",
        "* EfficientNetV2\n",
        "* GoogLeNet\n",
        "* Inception V3 - Inception modules with convolutional filters of different sizes\n",
        "* MaxVit\n",
        "* MNASNet\n",
        "* MobileNet V2\n",
        "* MobileNet V3\n",
        "* RegNet\n",
        "* ResNet - Residual Blocks\n",
        "* ResNeXt\n",
        "* ShuffleNet V2\n",
        "* SqueezeNet\n",
        "* SwinTransformer\n",
        "* VGG - Deep Networks of 16 or 19 layers, convolutions 3x3\n",
        "* VisionTransformer\n",
        "* Wide ResNets\n",
        "\n",
        "**Let's take something pretty straightforward from the architectural perspective. For example DenseNet looks appropriate for demonstrative goals. You can apply two different strategies:**\n",
        "\n",
        "1.   pretrained=**True**: use the pre-trained weights of the model which are trained on a larger database (recommended)\n",
        "2.   pretrained=**False**: begin with randomized weights and the densenet121 architecture.\n",
        "\n",
        "**Let's upload a model with pretraiend weights and check its architectural shape.**"
      ],
      "metadata": {
        "id": "xCzEcOJgICBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.densenet121(pretrained=True)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCDZSrcrGNaC",
        "outputId": "47f0373f-6d5b-42a7-a8e8-4ab4a06dc8f3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 159MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As the next step we can define some transformations step for our data before training our architectrue. It is up to you which transformations you think seems relevant.**"
      ],
      "metadata": {
        "id": "YupuinwsL8Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_cifar_train_densenet = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "transform_cifar_test_densenet = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])"
      ],
      "metadata": {
        "id": "TxzMS8-JTTht"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_train_pre = datasets.CIFAR10(root='data', train=True, transform=transform_cifar_train_densenet, download=True)\n",
        "cifar10_test_pre = datasets.CIFAR10(root='data', train=False, transform=transform_cifar_test_densenet, download=True)\n",
        "\n",
        "cifar10_loader_train_pre = DataLoader(cifar10_train_pre, batch_size=32, shuffle=True)\n",
        "cifar10_loader_test_pre = DataLoader(cifar10_test_pre, batch_size=32)"
      ],
      "metadata": {
        "id": "cYgEtbeqKjVp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Given we want to base our solution on some pretrained architecture we are not interested to retrain already existed layers in this model.**\n",
        "\n",
        "**First let's check whether layers are in \"training\" mode.**"
      ],
      "metadata": {
        "id": "V9aQ3bu1MV_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name,param.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCzqOtUA7nHX",
        "outputId": "96af6b19-49aa-4d02-ef6b-93ed05f23b39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.conv0.weight True\n",
            "features.norm0.weight True\n",
            "features.norm0.bias True\n",
            "features.denseblock1.denselayer1.norm1.weight True\n",
            "features.denseblock1.denselayer1.norm1.bias True\n",
            "features.denseblock1.denselayer1.conv1.weight True\n",
            "features.denseblock1.denselayer1.norm2.weight True\n",
            "features.denseblock1.denselayer1.norm2.bias True\n",
            "features.denseblock1.denselayer1.conv2.weight True\n",
            "features.denseblock1.denselayer2.norm1.weight True\n",
            "features.denseblock1.denselayer2.norm1.bias True\n",
            "features.denseblock1.denselayer2.conv1.weight True\n",
            "features.denseblock1.denselayer2.norm2.weight True\n",
            "features.denseblock1.denselayer2.norm2.bias True\n",
            "features.denseblock1.denselayer2.conv2.weight True\n",
            "features.denseblock1.denselayer3.norm1.weight True\n",
            "features.denseblock1.denselayer3.norm1.bias True\n",
            "features.denseblock1.denselayer3.conv1.weight True\n",
            "features.denseblock1.denselayer3.norm2.weight True\n",
            "features.denseblock1.denselayer3.norm2.bias True\n",
            "features.denseblock1.denselayer3.conv2.weight True\n",
            "features.denseblock1.denselayer4.norm1.weight True\n",
            "features.denseblock1.denselayer4.norm1.bias True\n",
            "features.denseblock1.denselayer4.conv1.weight True\n",
            "features.denseblock1.denselayer4.norm2.weight True\n",
            "features.denseblock1.denselayer4.norm2.bias True\n",
            "features.denseblock1.denselayer4.conv2.weight True\n",
            "features.denseblock1.denselayer5.norm1.weight True\n",
            "features.denseblock1.denselayer5.norm1.bias True\n",
            "features.denseblock1.denselayer5.conv1.weight True\n",
            "features.denseblock1.denselayer5.norm2.weight True\n",
            "features.denseblock1.denselayer5.norm2.bias True\n",
            "features.denseblock1.denselayer5.conv2.weight True\n",
            "features.denseblock1.denselayer6.norm1.weight True\n",
            "features.denseblock1.denselayer6.norm1.bias True\n",
            "features.denseblock1.denselayer6.conv1.weight True\n",
            "features.denseblock1.denselayer6.norm2.weight True\n",
            "features.denseblock1.denselayer6.norm2.bias True\n",
            "features.denseblock1.denselayer6.conv2.weight True\n",
            "features.transition1.norm.weight True\n",
            "features.transition1.norm.bias True\n",
            "features.transition1.conv.weight True\n",
            "features.denseblock2.denselayer1.norm1.weight True\n",
            "features.denseblock2.denselayer1.norm1.bias True\n",
            "features.denseblock2.denselayer1.conv1.weight True\n",
            "features.denseblock2.denselayer1.norm2.weight True\n",
            "features.denseblock2.denselayer1.norm2.bias True\n",
            "features.denseblock2.denselayer1.conv2.weight True\n",
            "features.denseblock2.denselayer2.norm1.weight True\n",
            "features.denseblock2.denselayer2.norm1.bias True\n",
            "features.denseblock2.denselayer2.conv1.weight True\n",
            "features.denseblock2.denselayer2.norm2.weight True\n",
            "features.denseblock2.denselayer2.norm2.bias True\n",
            "features.denseblock2.denselayer2.conv2.weight True\n",
            "features.denseblock2.denselayer3.norm1.weight True\n",
            "features.denseblock2.denselayer3.norm1.bias True\n",
            "features.denseblock2.denselayer3.conv1.weight True\n",
            "features.denseblock2.denselayer3.norm2.weight True\n",
            "features.denseblock2.denselayer3.norm2.bias True\n",
            "features.denseblock2.denselayer3.conv2.weight True\n",
            "features.denseblock2.denselayer4.norm1.weight True\n",
            "features.denseblock2.denselayer4.norm1.bias True\n",
            "features.denseblock2.denselayer4.conv1.weight True\n",
            "features.denseblock2.denselayer4.norm2.weight True\n",
            "features.denseblock2.denselayer4.norm2.bias True\n",
            "features.denseblock2.denselayer4.conv2.weight True\n",
            "features.denseblock2.denselayer5.norm1.weight True\n",
            "features.denseblock2.denselayer5.norm1.bias True\n",
            "features.denseblock2.denselayer5.conv1.weight True\n",
            "features.denseblock2.denselayer5.norm2.weight True\n",
            "features.denseblock2.denselayer5.norm2.bias True\n",
            "features.denseblock2.denselayer5.conv2.weight True\n",
            "features.denseblock2.denselayer6.norm1.weight True\n",
            "features.denseblock2.denselayer6.norm1.bias True\n",
            "features.denseblock2.denselayer6.conv1.weight True\n",
            "features.denseblock2.denselayer6.norm2.weight True\n",
            "features.denseblock2.denselayer6.norm2.bias True\n",
            "features.denseblock2.denselayer6.conv2.weight True\n",
            "features.denseblock2.denselayer7.norm1.weight True\n",
            "features.denseblock2.denselayer7.norm1.bias True\n",
            "features.denseblock2.denselayer7.conv1.weight True\n",
            "features.denseblock2.denselayer7.norm2.weight True\n",
            "features.denseblock2.denselayer7.norm2.bias True\n",
            "features.denseblock2.denselayer7.conv2.weight True\n",
            "features.denseblock2.denselayer8.norm1.weight True\n",
            "features.denseblock2.denselayer8.norm1.bias True\n",
            "features.denseblock2.denselayer8.conv1.weight True\n",
            "features.denseblock2.denselayer8.norm2.weight True\n",
            "features.denseblock2.denselayer8.norm2.bias True\n",
            "features.denseblock2.denselayer8.conv2.weight True\n",
            "features.denseblock2.denselayer9.norm1.weight True\n",
            "features.denseblock2.denselayer9.norm1.bias True\n",
            "features.denseblock2.denselayer9.conv1.weight True\n",
            "features.denseblock2.denselayer9.norm2.weight True\n",
            "features.denseblock2.denselayer9.norm2.bias True\n",
            "features.denseblock2.denselayer9.conv2.weight True\n",
            "features.denseblock2.denselayer10.norm1.weight True\n",
            "features.denseblock2.denselayer10.norm1.bias True\n",
            "features.denseblock2.denselayer10.conv1.weight True\n",
            "features.denseblock2.denselayer10.norm2.weight True\n",
            "features.denseblock2.denselayer10.norm2.bias True\n",
            "features.denseblock2.denselayer10.conv2.weight True\n",
            "features.denseblock2.denselayer11.norm1.weight True\n",
            "features.denseblock2.denselayer11.norm1.bias True\n",
            "features.denseblock2.denselayer11.conv1.weight True\n",
            "features.denseblock2.denselayer11.norm2.weight True\n",
            "features.denseblock2.denselayer11.norm2.bias True\n",
            "features.denseblock2.denselayer11.conv2.weight True\n",
            "features.denseblock2.denselayer12.norm1.weight True\n",
            "features.denseblock2.denselayer12.norm1.bias True\n",
            "features.denseblock2.denselayer12.conv1.weight True\n",
            "features.denseblock2.denselayer12.norm2.weight True\n",
            "features.denseblock2.denselayer12.norm2.bias True\n",
            "features.denseblock2.denselayer12.conv2.weight True\n",
            "features.transition2.norm.weight True\n",
            "features.transition2.norm.bias True\n",
            "features.transition2.conv.weight True\n",
            "features.denseblock3.denselayer1.norm1.weight True\n",
            "features.denseblock3.denselayer1.norm1.bias True\n",
            "features.denseblock3.denselayer1.conv1.weight True\n",
            "features.denseblock3.denselayer1.norm2.weight True\n",
            "features.denseblock3.denselayer1.norm2.bias True\n",
            "features.denseblock3.denselayer1.conv2.weight True\n",
            "features.denseblock3.denselayer2.norm1.weight True\n",
            "features.denseblock3.denselayer2.norm1.bias True\n",
            "features.denseblock3.denselayer2.conv1.weight True\n",
            "features.denseblock3.denselayer2.norm2.weight True\n",
            "features.denseblock3.denselayer2.norm2.bias True\n",
            "features.denseblock3.denselayer2.conv2.weight True\n",
            "features.denseblock3.denselayer3.norm1.weight True\n",
            "features.denseblock3.denselayer3.norm1.bias True\n",
            "features.denseblock3.denselayer3.conv1.weight True\n",
            "features.denseblock3.denselayer3.norm2.weight True\n",
            "features.denseblock3.denselayer3.norm2.bias True\n",
            "features.denseblock3.denselayer3.conv2.weight True\n",
            "features.denseblock3.denselayer4.norm1.weight True\n",
            "features.denseblock3.denselayer4.norm1.bias True\n",
            "features.denseblock3.denselayer4.conv1.weight True\n",
            "features.denseblock3.denselayer4.norm2.weight True\n",
            "features.denseblock3.denselayer4.norm2.bias True\n",
            "features.denseblock3.denselayer4.conv2.weight True\n",
            "features.denseblock3.denselayer5.norm1.weight True\n",
            "features.denseblock3.denselayer5.norm1.bias True\n",
            "features.denseblock3.denselayer5.conv1.weight True\n",
            "features.denseblock3.denselayer5.norm2.weight True\n",
            "features.denseblock3.denselayer5.norm2.bias True\n",
            "features.denseblock3.denselayer5.conv2.weight True\n",
            "features.denseblock3.denselayer6.norm1.weight True\n",
            "features.denseblock3.denselayer6.norm1.bias True\n",
            "features.denseblock3.denselayer6.conv1.weight True\n",
            "features.denseblock3.denselayer6.norm2.weight True\n",
            "features.denseblock3.denselayer6.norm2.bias True\n",
            "features.denseblock3.denselayer6.conv2.weight True\n",
            "features.denseblock3.denselayer7.norm1.weight True\n",
            "features.denseblock3.denselayer7.norm1.bias True\n",
            "features.denseblock3.denselayer7.conv1.weight True\n",
            "features.denseblock3.denselayer7.norm2.weight True\n",
            "features.denseblock3.denselayer7.norm2.bias True\n",
            "features.denseblock3.denselayer7.conv2.weight True\n",
            "features.denseblock3.denselayer8.norm1.weight True\n",
            "features.denseblock3.denselayer8.norm1.bias True\n",
            "features.denseblock3.denselayer8.conv1.weight True\n",
            "features.denseblock3.denselayer8.norm2.weight True\n",
            "features.denseblock3.denselayer8.norm2.bias True\n",
            "features.denseblock3.denselayer8.conv2.weight True\n",
            "features.denseblock3.denselayer9.norm1.weight True\n",
            "features.denseblock3.denselayer9.norm1.bias True\n",
            "features.denseblock3.denselayer9.conv1.weight True\n",
            "features.denseblock3.denselayer9.norm2.weight True\n",
            "features.denseblock3.denselayer9.norm2.bias True\n",
            "features.denseblock3.denselayer9.conv2.weight True\n",
            "features.denseblock3.denselayer10.norm1.weight True\n",
            "features.denseblock3.denselayer10.norm1.bias True\n",
            "features.denseblock3.denselayer10.conv1.weight True\n",
            "features.denseblock3.denselayer10.norm2.weight True\n",
            "features.denseblock3.denselayer10.norm2.bias True\n",
            "features.denseblock3.denselayer10.conv2.weight True\n",
            "features.denseblock3.denselayer11.norm1.weight True\n",
            "features.denseblock3.denselayer11.norm1.bias True\n",
            "features.denseblock3.denselayer11.conv1.weight True\n",
            "features.denseblock3.denselayer11.norm2.weight True\n",
            "features.denseblock3.denselayer11.norm2.bias True\n",
            "features.denseblock3.denselayer11.conv2.weight True\n",
            "features.denseblock3.denselayer12.norm1.weight True\n",
            "features.denseblock3.denselayer12.norm1.bias True\n",
            "features.denseblock3.denselayer12.conv1.weight True\n",
            "features.denseblock3.denselayer12.norm2.weight True\n",
            "features.denseblock3.denselayer12.norm2.bias True\n",
            "features.denseblock3.denselayer12.conv2.weight True\n",
            "features.denseblock3.denselayer13.norm1.weight True\n",
            "features.denseblock3.denselayer13.norm1.bias True\n",
            "features.denseblock3.denselayer13.conv1.weight True\n",
            "features.denseblock3.denselayer13.norm2.weight True\n",
            "features.denseblock3.denselayer13.norm2.bias True\n",
            "features.denseblock3.denselayer13.conv2.weight True\n",
            "features.denseblock3.denselayer14.norm1.weight True\n",
            "features.denseblock3.denselayer14.norm1.bias True\n",
            "features.denseblock3.denselayer14.conv1.weight True\n",
            "features.denseblock3.denselayer14.norm2.weight True\n",
            "features.denseblock3.denselayer14.norm2.bias True\n",
            "features.denseblock3.denselayer14.conv2.weight True\n",
            "features.denseblock3.denselayer15.norm1.weight True\n",
            "features.denseblock3.denselayer15.norm1.bias True\n",
            "features.denseblock3.denselayer15.conv1.weight True\n",
            "features.denseblock3.denselayer15.norm2.weight True\n",
            "features.denseblock3.denselayer15.norm2.bias True\n",
            "features.denseblock3.denselayer15.conv2.weight True\n",
            "features.denseblock3.denselayer16.norm1.weight True\n",
            "features.denseblock3.denselayer16.norm1.bias True\n",
            "features.denseblock3.denselayer16.conv1.weight True\n",
            "features.denseblock3.denselayer16.norm2.weight True\n",
            "features.denseblock3.denselayer16.norm2.bias True\n",
            "features.denseblock3.denselayer16.conv2.weight True\n",
            "features.denseblock3.denselayer17.norm1.weight True\n",
            "features.denseblock3.denselayer17.norm1.bias True\n",
            "features.denseblock3.denselayer17.conv1.weight True\n",
            "features.denseblock3.denselayer17.norm2.weight True\n",
            "features.denseblock3.denselayer17.norm2.bias True\n",
            "features.denseblock3.denselayer17.conv2.weight True\n",
            "features.denseblock3.denselayer18.norm1.weight True\n",
            "features.denseblock3.denselayer18.norm1.bias True\n",
            "features.denseblock3.denselayer18.conv1.weight True\n",
            "features.denseblock3.denselayer18.norm2.weight True\n",
            "features.denseblock3.denselayer18.norm2.bias True\n",
            "features.denseblock3.denselayer18.conv2.weight True\n",
            "features.denseblock3.denselayer19.norm1.weight True\n",
            "features.denseblock3.denselayer19.norm1.bias True\n",
            "features.denseblock3.denselayer19.conv1.weight True\n",
            "features.denseblock3.denselayer19.norm2.weight True\n",
            "features.denseblock3.denselayer19.norm2.bias True\n",
            "features.denseblock3.denselayer19.conv2.weight True\n",
            "features.denseblock3.denselayer20.norm1.weight True\n",
            "features.denseblock3.denselayer20.norm1.bias True\n",
            "features.denseblock3.denselayer20.conv1.weight True\n",
            "features.denseblock3.denselayer20.norm2.weight True\n",
            "features.denseblock3.denselayer20.norm2.bias True\n",
            "features.denseblock3.denselayer20.conv2.weight True\n",
            "features.denseblock3.denselayer21.norm1.weight True\n",
            "features.denseblock3.denselayer21.norm1.bias True\n",
            "features.denseblock3.denselayer21.conv1.weight True\n",
            "features.denseblock3.denselayer21.norm2.weight True\n",
            "features.denseblock3.denselayer21.norm2.bias True\n",
            "features.denseblock3.denselayer21.conv2.weight True\n",
            "features.denseblock3.denselayer22.norm1.weight True\n",
            "features.denseblock3.denselayer22.norm1.bias True\n",
            "features.denseblock3.denselayer22.conv1.weight True\n",
            "features.denseblock3.denselayer22.norm2.weight True\n",
            "features.denseblock3.denselayer22.norm2.bias True\n",
            "features.denseblock3.denselayer22.conv2.weight True\n",
            "features.denseblock3.denselayer23.norm1.weight True\n",
            "features.denseblock3.denselayer23.norm1.bias True\n",
            "features.denseblock3.denselayer23.conv1.weight True\n",
            "features.denseblock3.denselayer23.norm2.weight True\n",
            "features.denseblock3.denselayer23.norm2.bias True\n",
            "features.denseblock3.denselayer23.conv2.weight True\n",
            "features.denseblock3.denselayer24.norm1.weight True\n",
            "features.denseblock3.denselayer24.norm1.bias True\n",
            "features.denseblock3.denselayer24.conv1.weight True\n",
            "features.denseblock3.denselayer24.norm2.weight True\n",
            "features.denseblock3.denselayer24.norm2.bias True\n",
            "features.denseblock3.denselayer24.conv2.weight True\n",
            "features.transition3.norm.weight True\n",
            "features.transition3.norm.bias True\n",
            "features.transition3.conv.weight True\n",
            "features.denseblock4.denselayer1.norm1.weight True\n",
            "features.denseblock4.denselayer1.norm1.bias True\n",
            "features.denseblock4.denselayer1.conv1.weight True\n",
            "features.denseblock4.denselayer1.norm2.weight True\n",
            "features.denseblock4.denselayer1.norm2.bias True\n",
            "features.denseblock4.denselayer1.conv2.weight True\n",
            "features.denseblock4.denselayer2.norm1.weight True\n",
            "features.denseblock4.denselayer2.norm1.bias True\n",
            "features.denseblock4.denselayer2.conv1.weight True\n",
            "features.denseblock4.denselayer2.norm2.weight True\n",
            "features.denseblock4.denselayer2.norm2.bias True\n",
            "features.denseblock4.denselayer2.conv2.weight True\n",
            "features.denseblock4.denselayer3.norm1.weight True\n",
            "features.denseblock4.denselayer3.norm1.bias True\n",
            "features.denseblock4.denselayer3.conv1.weight True\n",
            "features.denseblock4.denselayer3.norm2.weight True\n",
            "features.denseblock4.denselayer3.norm2.bias True\n",
            "features.denseblock4.denselayer3.conv2.weight True\n",
            "features.denseblock4.denselayer4.norm1.weight True\n",
            "features.denseblock4.denselayer4.norm1.bias True\n",
            "features.denseblock4.denselayer4.conv1.weight True\n",
            "features.denseblock4.denselayer4.norm2.weight True\n",
            "features.denseblock4.denselayer4.norm2.bias True\n",
            "features.denseblock4.denselayer4.conv2.weight True\n",
            "features.denseblock4.denselayer5.norm1.weight True\n",
            "features.denseblock4.denselayer5.norm1.bias True\n",
            "features.denseblock4.denselayer5.conv1.weight True\n",
            "features.denseblock4.denselayer5.norm2.weight True\n",
            "features.denseblock4.denselayer5.norm2.bias True\n",
            "features.denseblock4.denselayer5.conv2.weight True\n",
            "features.denseblock4.denselayer6.norm1.weight True\n",
            "features.denseblock4.denselayer6.norm1.bias True\n",
            "features.denseblock4.denselayer6.conv1.weight True\n",
            "features.denseblock4.denselayer6.norm2.weight True\n",
            "features.denseblock4.denselayer6.norm2.bias True\n",
            "features.denseblock4.denselayer6.conv2.weight True\n",
            "features.denseblock4.denselayer7.norm1.weight True\n",
            "features.denseblock4.denselayer7.norm1.bias True\n",
            "features.denseblock4.denselayer7.conv1.weight True\n",
            "features.denseblock4.denselayer7.norm2.weight True\n",
            "features.denseblock4.denselayer7.norm2.bias True\n",
            "features.denseblock4.denselayer7.conv2.weight True\n",
            "features.denseblock4.denselayer8.norm1.weight True\n",
            "features.denseblock4.denselayer8.norm1.bias True\n",
            "features.denseblock4.denselayer8.conv1.weight True\n",
            "features.denseblock4.denselayer8.norm2.weight True\n",
            "features.denseblock4.denselayer8.norm2.bias True\n",
            "features.denseblock4.denselayer8.conv2.weight True\n",
            "features.denseblock4.denselayer9.norm1.weight True\n",
            "features.denseblock4.denselayer9.norm1.bias True\n",
            "features.denseblock4.denselayer9.conv1.weight True\n",
            "features.denseblock4.denselayer9.norm2.weight True\n",
            "features.denseblock4.denselayer9.norm2.bias True\n",
            "features.denseblock4.denselayer9.conv2.weight True\n",
            "features.denseblock4.denselayer10.norm1.weight True\n",
            "features.denseblock4.denselayer10.norm1.bias True\n",
            "features.denseblock4.denselayer10.conv1.weight True\n",
            "features.denseblock4.denselayer10.norm2.weight True\n",
            "features.denseblock4.denselayer10.norm2.bias True\n",
            "features.denseblock4.denselayer10.conv2.weight True\n",
            "features.denseblock4.denselayer11.norm1.weight True\n",
            "features.denseblock4.denselayer11.norm1.bias True\n",
            "features.denseblock4.denselayer11.conv1.weight True\n",
            "features.denseblock4.denselayer11.norm2.weight True\n",
            "features.denseblock4.denselayer11.norm2.bias True\n",
            "features.denseblock4.denselayer11.conv2.weight True\n",
            "features.denseblock4.denselayer12.norm1.weight True\n",
            "features.denseblock4.denselayer12.norm1.bias True\n",
            "features.denseblock4.denselayer12.conv1.weight True\n",
            "features.denseblock4.denselayer12.norm2.weight True\n",
            "features.denseblock4.denselayer12.norm2.bias True\n",
            "features.denseblock4.denselayer12.conv2.weight True\n",
            "features.denseblock4.denselayer13.norm1.weight True\n",
            "features.denseblock4.denselayer13.norm1.bias True\n",
            "features.denseblock4.denselayer13.conv1.weight True\n",
            "features.denseblock4.denselayer13.norm2.weight True\n",
            "features.denseblock4.denselayer13.norm2.bias True\n",
            "features.denseblock4.denselayer13.conv2.weight True\n",
            "features.denseblock4.denselayer14.norm1.weight True\n",
            "features.denseblock4.denselayer14.norm1.bias True\n",
            "features.denseblock4.denselayer14.conv1.weight True\n",
            "features.denseblock4.denselayer14.norm2.weight True\n",
            "features.denseblock4.denselayer14.norm2.bias True\n",
            "features.denseblock4.denselayer14.conv2.weight True\n",
            "features.denseblock4.denselayer15.norm1.weight True\n",
            "features.denseblock4.denselayer15.norm1.bias True\n",
            "features.denseblock4.denselayer15.conv1.weight True\n",
            "features.denseblock4.denselayer15.norm2.weight True\n",
            "features.denseblock4.denselayer15.norm2.bias True\n",
            "features.denseblock4.denselayer15.conv2.weight True\n",
            "features.denseblock4.denselayer16.norm1.weight True\n",
            "features.denseblock4.denselayer16.norm1.bias True\n",
            "features.denseblock4.denselayer16.conv1.weight True\n",
            "features.denseblock4.denselayer16.norm2.weight True\n",
            "features.denseblock4.denselayer16.norm2.bias True\n",
            "features.denseblock4.denselayer16.conv2.weight True\n",
            "features.norm5.weight True\n",
            "features.norm5.bias True\n",
            "classifier.weight True\n",
            "classifier.bias True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next let's change this by applying False mode for each layer in the pretrained model. Since we know that classifier layer is responsible specifically for distinguising classes we can replace it by some new parametric module. For this purpose we can also apply Sequential method from the previous section.**"
      ],
      "metadata": {
        "id": "9raVM8IHM9Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "wNo4xpBHR9jj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's take a layer for retraining...**"
      ],
      "metadata": {
        "id": "UXgFDYr14uyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.features.denseblock4.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "y2UB_H5R4t1n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model.classifier.in_features"
      ],
      "metadata": {
        "id": "DjZ-ugJ2Re_Y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier = nn.Sequential(\n",
        "                        nn.Linear(num_features, 256),\n",
        "                        nn.LeakyReLU(),\n",
        "                        nn.Dropout(0.3),\n",
        "                        nn.Linear(256, 10),\n",
        "                        nn.LogSoftmax(dim=1))\n",
        "\n",
        "                        # nn.Softmax(dim=1))"
      ],
      "metadata": {
        "id": "rTXIdDvPKwBf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 40\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "save_file_name = 'model-cifar-pretrained.pt'\n",
        "\n",
        "train(model, cifar10_loader_train_pre, cifar10_loader_test_pre, optimizer = optimizer,\n",
        "      n_epochs = n_epochs, criterion = torch.nn.NLLLoss(), max_epochs_stop = 5, save_file = save_file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVDywuWRNMD0",
        "outputId": "4e7b9f54-858c-4d85-ad4b-0e75976fab3f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 \tTraining Loss: 1.383521 \tTest Loss: 1.067161\n",
            "Training Accuracy: 51.75%\t Test Accuracy: 63.21%\n",
            "Test loss decreased (inf --> 1.067161).  Saving model ...\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 1.069990 \tTest Loss: 0.992979\n",
            "Training Accuracy: 62.60%\t Test Accuracy: 65.96%\n",
            "Test loss decreased (1.067161 --> 0.992979).  Saving model ...\n",
            "\n",
            "Epoch: 3 \tTraining Loss: 0.973434 \tTest Loss: 0.972500\n",
            "Training Accuracy: 65.93%\t Test Accuracy: 66.62%\n",
            "Test loss decreased (0.992979 --> 0.972500).  Saving model ...\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 0.892809 \tTest Loss: 0.960244\n",
            "Training Accuracy: 68.72%\t Test Accuracy: 66.93%\n",
            "Test loss decreased (0.972500 --> 0.960244).  Saving model ...\n",
            "\n",
            "Epoch: 5 \tTraining Loss: 0.838915 \tTest Loss: 0.977106\n",
            "Training Accuracy: 70.60%\t Test Accuracy: 67.76%\n",
            "1 epochs with no improvement.\n",
            "\n",
            "Epoch: 6 \tTraining Loss: 0.784997 \tTest Loss: 0.959945\n",
            "Training Accuracy: 72.52%\t Test Accuracy: 67.85%\n",
            "Test loss decreased (0.960244 --> 0.959945).  Saving model ...\n",
            "\n",
            "Epoch: 7 \tTraining Loss: 0.741334 \tTest Loss: 0.969939\n",
            "Training Accuracy: 73.96%\t Test Accuracy: 68.17%\n",
            "1 epochs with no improvement.\n",
            "\n",
            "Epoch: 8 \tTraining Loss: 0.696426 \tTest Loss: 0.965538\n",
            "Training Accuracy: 75.39%\t Test Accuracy: 68.39%\n",
            "2 epochs with no improvement.\n",
            "\n",
            "Epoch: 9 \tTraining Loss: 0.659817 \tTest Loss: 1.041835\n",
            "Training Accuracy: 76.75%\t Test Accuracy: 67.19%\n",
            "3 epochs with no improvement.\n",
            "\n",
            "Epoch: 10 \tTraining Loss: 0.630778 \tTest Loss: 1.013398\n",
            "Training Accuracy: 77.63%\t Test Accuracy: 68.25%\n",
            "4 epochs with no improvement.\n",
            "\n",
            "Epoch: 11 \tTraining Loss: 0.600800 \tTest Loss: 1.042467\n",
            "Training Accuracy: 78.91%\t Test Accuracy: 67.76%\n",
            "5 epochs with no improvement.\n",
            "\n",
            "Epoch: 12 \tTraining Loss: 0.577387 \tTest Loss: 1.040321\n",
            "Training Accuracy: 79.77%\t Test Accuracy: 68.58%\n",
            "6 epochs with no improvement.\n",
            "\n",
            "Epoch: 13 \tTraining Loss: 0.557091 \tTest Loss: 1.001666\n",
            "Training Accuracy: 80.32%\t Test Accuracy: 68.43%\n",
            "7 epochs with no improvement.\n",
            "\n",
            "Epoch: 14 \tTraining Loss: 0.532860 \tTest Loss: 1.018558\n",
            "Training Accuracy: 81.28%\t Test Accuracy: 68.59%\n",
            "8 epochs with no improvement.\n",
            "\n",
            "Epoch: 15 \tTraining Loss: 0.515158 \tTest Loss: 1.054314\n",
            "Training Accuracy: 81.83%\t Test Accuracy: 67.66%\n",
            "9 epochs with no improvement.\n",
            "\n",
            "Epoch: 16 \tTraining Loss: 0.492764 \tTest Loss: 1.087710\n",
            "Training Accuracy: 82.53%\t Test Accuracy: 67.53%\n",
            "10 epochs with no improvement.\n",
            "Early Stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AS we might notice result is not that drastically better compared to our initial model with convolution layers. Still you can try some new models as well as new a new shape for a classifier module.**\n",
        "\n",
        "**That's it for today...**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "AjfwHxAtN6VY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Home Task**"
      ],
      "metadata": {
        "id": "9N8Lx8eVryu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can choose any multi-label classification dataset for the following task.\n",
        "\n",
        "\n",
        "1.   In this task you need to take a Fashion MNIST dataset and achieve **>85%** accuracy. You are able to improve the initial architecture using unused methods and tricks to improve the final result (max pooling, dropout, etc.). BUT do not make your model too complex (max 4 densed layers excluding convoltion and softmax layers).\n",
        "\n",
        "2.  Explain what methods (or model additions) have had the biggest impact on the test set accuracy. Provide graphical comparison in metrics between models of different architectures.\n",
        "\n",
        "3.  Train an additional architecture using any pretrained model to achieve comparable accuracy of **~85%** or higher. Try to beat a result obtained in the 1st task.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "*   You should have your own classification layer (usually the last one) or layer that is responsible for classification. You can add a new layer if a classification layer is initially absent\n",
        "*   You are able to choose at least one layer to retrain from the pretrained architecture\n",
        "*   Architecture should beat the initial model in the 1st task\n",
        "*   You  can choose any architecture from the pretrained list of [PyTorch](https://https://docs.pytorch.org/vision/main/models.html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Remember that you have approximately **7 days** to complete these tasks. You are allowed to use any avaialble computational resource.\n",
        "\n",
        "**Expected result:** uploaded Jupyter notebook with completed tasks to the Moodle assignment section."
      ],
      "metadata": {
        "id": "HB-PX6DlOh-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST"
      ],
      "metadata": {
        "id": "YPxJvBJ1OBYb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "LAuI_uY6g-J_",
        "outputId": "6086017a-e787-4de4-c85d-a53d60019c69"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.7MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 204kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.78MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 11.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 5')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# *** YOUR CODE ***"
      ],
      "metadata": {
        "id": "yJWy76KqhATs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}